CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node=4 pretraining_gimlet.py   --model_name_or_path t5-small   --tokenizer_name t5-small   --transformer_backbone gimlet   --do_train   --train_file haitengzhao/molecule_property_instruction   --transform_in_collator   --per_device_train_batch_size 64   --gradient_accumulation_steps 1   --per_device_eval_batch_size 200   --line_by_line   --loss_reduction_method sentence   --save_steps 10000   --output_dir ckpts/gimlet_new1
